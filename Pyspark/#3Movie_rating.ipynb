{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit01bdc4eb7c5d4c04ab8726a44f243631",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
    "## PEC3\n",
    "### Practica sobre la predicción del ratings de las películas\n",
    "\n",
    "Uno de los usos más comunes de big data es predecir lo que quieren los usuarios. Esto permite que Google le muestre anuncios relevantes, Amazon le recomiende productos relevantes y Netflix le recomiende películas que le pueden gustar. Este laboratorio demostrará cómo podemos usar Apache Spark para recomendar películas a un usuario. Comenzaremos con algunas técnicas básicas y luego usaremos el método de mínimos cuadrados alternos de la biblioteca Spark ML para hacer predicciones más sofisticadas.\n",
    "\n",
    "Para esta práctica de laboratorio, usaremos un subconjunto de datos de 100 mil calificaciones. Este conjunto de datos está premontado en Databricks y proviene del conjunto de datos de calificación de referencia estable de MovieLens. Sin embargo, el mismo código que escriba también funcionará en el conjunto de datos completo (aunque es probable que la ejecución con el conjunto de datos completo en Community Edition lleve bastante tiempo).\n",
    "\n",
    "En este laboratorio:\n",
    "\n",
    "Parte 0: Preliminares\n",
    "\n",
    "Parte 1: Recomendaciones básicas\n",
    "\n",
    "Parte 2: filtrado colaborativo\n",
    "\n",
    "Parte 3: Predicciones para usted mismo\n",
    "\n",
    "Como se mencionó durante el primer laboratorio de Learning Spark, piense detenidamente antes de llamar a collect () en cualquier conjunto de datos. Cuando está utilizando un conjunto de datos pequeño, llamar a collect () y luego usar Python para tener una idea de los datos localmente (en el programa del controlador) funcionará bien, pero esto no funcionará cuando esté utilizando un conjunto de datos grande que no caben en la memoria en una máquina."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "import os.path\n",
    "sc = pyspark.SparkContext(master=\"local[1]\",appName='Movies_ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path datasets\n",
    "\n",
    "import os\n",
    "datasets_dir= '/home/gonzalezjulvez/Documentos/Projects_Github/Projects/Pyspark/data/Movies/'\n",
    "\n",
    "movies_path = datasets_dir+'movies.csv'\n",
    "ratings_path = datasets_dir+'ratings.csv'\n"
   ]
  },
  {
   "source": [
    "Para la carga de los archivos vamos a acelerar aún más las cosas especificando explícitamente el esquema DataFrame. (Cuando el adaptador Spark CSV infiere el esquema de un archivo CSV, tiene que realizar una pasada adicional sobre el archivo. Eso ralentizará las cosas aquí, y no es realmente necesario)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema_movies = StructType([StructField('ID', IntegerType(),True),\n",
    "                            StructField('title',StringType(),True)])\n",
    "\n",
    "schema_ratings = StructType([StructField('userID',IntegerType(),True),\n",
    "                             StructField('movieID', IntegerType(),True),\n",
    "                             StructField('rating',DoubleType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StructType(List(StructField(userID,IntegerType,true),StructField(movieID,IntegerType,true),StructField(rating,DoubleType,true)))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "schema_ratings"
   ]
  },
  {
   "source": [
    "## Cargar y Caché\n",
    "\n",
    "Vamos a tener mucho acceso a estos datos. En lugar de leerlo una y otra vez, almacenaremos en caché tanto las películas DataFrame como las clasificaciones DataFrame en la memoria.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Load Datasets\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "raw_df_movies = sqlContext.read.format('csv').options(header='True', delimiter=',', inferschema='False').schema(schema_movies).load(movies_path)\n",
    "raw_df_ratings = sqlContext.read.format('csv').options(header='True', delimiter=',', inferschema='False').schema(schema_ratings).load(ratings_path)\n",
    "\n",
    "# Remove useless columns. \n",
    "df_movies = raw_df_movies.drop('Genres').withColumnRenamed('movieID', 'ID')\n",
    "df_ratings = raw_df_ratings.drop('Timestamp')\n",
    "\n",
    "# Load in cache\n",
    "df_movies.cache()\n",
    "df_ratings.cache()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[userID: int, movieID: int, rating: double]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 9742 movies with 100836 ratings in our datasets\n",
      "+---+----------------+\n",
      "| ID|           title|\n",
      "+---+----------------+\n",
      "|  1|Toy Story (1995)|\n",
      "|  2|  Jumanji (1995)|\n",
      "+---+----------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+------+-------+------+\n",
      "|userID|movieID|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count columns and show table\n",
    "\n",
    "print('There are {0} movies with {1} ratings in our datasets'.format(df_movies.count(), df_ratings.count()))\n",
    "\n",
    "df_movies.show(2)\n",
    "df_ratings.show(2)"
   ]
  },
  {
   "source": [
    "## Parte 1: Recomendaciones básicas\n",
    "\n",
    "Una forma de recomendar películas es recomendar siempre las películas con la calificación promedio más alta. En esta parte, usaremos Spark para encontrar el nombre, el número de calificaciones y la calificación promedio de las 20 películas con la calificación promedio más alta y al menos 170 reseñas. Queremos filtrar nuestras películas con calificaciones altas pero mayores o iguales a 170 reseñas porque es posible que las películas con pocas reseñas no tengan un gran atractivo para todos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### (1a) Películas con calificaciones promedio más altas\n",
    "\n",
    "\n",
    "Recuerde que ratings_df contiene tres columnas:\n",
    "\n",
    "- El ID del usuario que calificó la película.\n",
    "- ID de la película que se califica\n",
    "- La nota.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create table\n",
    "sqlContext.sql('DROP TABLE IF EXISTS ratings')\n",
    "sqlContext.registerDataFrameAsTable(df_ratings, 'ratings')\n",
    "sqlContext.sql('DROP TABLE IF EXISTS movies')\n",
    "sqlContext.registerDataFrameAsTable(df_movies, 'movies')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movie_ids_with_avg_ratings_df = sqlContext.sql('Select movieID, COUNT(rating) as count, AVG(rating) as rating FROM ratings GROUP BY movieID')\n",
    "sqlContext.sql('DROP TABLE IF EXISTS movie_ids_with_avg_ratings')\n",
    "sqlContext.registerDataFrameAsTable(movie_ids_with_avg_ratings_df, 'movie_ids_with_avg_ratings')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---+--------------------+\n| ID|               title|\n+---+--------------------+\n|  1|    Toy Story (1995)|\n|  2|      Jumanji (1995)|\n|  3|Grumpier Old Men ...|\n|  4|Waiting to Exhale...|\n|  5|Father of the Bri...|\n|  6|         Heat (1995)|\n|  7|      Sabrina (1995)|\n|  8| Tom and Huck (1995)|\n|  9| Sudden Death (1995)|\n| 10|    GoldenEye (1995)|\n+---+--------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT * FROM movies').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+--------------------+-----+-----------------+\n|movieID|               title|count|           rating|\n+-------+--------------------+-----+-----------------+\n|    356| Forrest Gump (1994)|  329|4.164133738601824|\n|    318|Shawshank Redempt...|  317|4.429022082018927|\n|    296| Pulp Fiction (1994)|  307|4.197068403908795|\n|    593|Silence of the La...|  279|4.161290322580645|\n|   2571|  Matrix, The (1999)|  278|4.192446043165468|\n|    260|Star Wars: Episod...|  251|4.231075697211155|\n|    480|Jurassic Park (1993)|  238|             3.75|\n|    110|   Braveheart (1995)|  237|4.031645569620253|\n|    589|Terminator 2: Jud...|  224|3.970982142857143|\n|    527|Schindler's List ...|  220|            4.225|\n+-------+--------------------+-----+-----------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "movie_names_with_avg_ratings_df = sqlContext.sql(\" SELECT r.movieID, m.title, r.count, r.rating FROM movie_ids_with_avg_ratings r, movies m WHERE m.ID=r.movieID ORDER BY count DESC\")\n",
    "movie_names_with_avg_ratings_df.show(10)"
   ]
  },
  {
   "source": [
    "Ahora que tenemos un DataFrame de las películas con calificaciones promedio más altas, podemos usar Spark para determinar las 20 películas con calificaciones promedio más altas y al menos 170 reseñas.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+--------------------+-----+------------------+\n|movieID|               title|count|            rating|\n+-------+--------------------+-----+------------------+\n|    356| Forrest Gump (1994)|  329| 4.164133738601824|\n|    318|Shawshank Redempt...|  317| 4.429022082018927|\n|    296| Pulp Fiction (1994)|  307| 4.197068403908795|\n|    593|Silence of the La...|  279| 4.161290322580645|\n|   2571|  Matrix, The (1999)|  278| 4.192446043165468|\n|    260|Star Wars: Episod...|  251| 4.231075697211155|\n|    480|Jurassic Park (1993)|  238|              3.75|\n|    110|   Braveheart (1995)|  237| 4.031645569620253|\n|    589|Terminator 2: Jud...|  224| 3.970982142857143|\n|    527|Schindler's List ...|  220|             4.225|\n|   2959|   Fight Club (1999)|  218| 4.272935779816514|\n|      1|    Toy Story (1995)|  215|3.9209302325581397|\n|   1196|Star Wars: Episod...|  211|4.2156398104265405|\n|   2858|American Beauty (...|  204| 4.056372549019608|\n|     50|Usual Suspects, T...|  204| 4.237745098039215|\n|     47|Seven (a.k.a. Se7...|  203|3.9753694581280787|\n|    780|Independence Day ...|  202|3.4455445544554455|\n|    150|    Apollo 13 (1995)|  201| 3.845771144278607|\n|   1198|Raiders of the Lo...|  200|            4.2075|\n|   4993|Lord of the Rings...|  198| 4.106060606060606|\n+-------+--------------------+-----+------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "movies_with_170_ratings = movie_names_with_avg_ratings_df[movie_names_with_avg_ratings_df['count']>=170]\n",
    "movies_with_170_ratings.show(20)"
   ]
  },
  {
   "source": [
    "## Parte 2: filtrado colaborativo\n",
    "\n",
    "En este curso, ha aprendido sobre muchas de las transformaciones y acciones básicas que Spark nos permite aplicar a conjuntos de datos distribuidos. Spark también expone algunas funciones de nivel superior; en particular, Machine Learning usando un componente de Spark llamado MLlib. En esta parte, aprenderá a usar MLlib para hacer recomendaciones de películas personalizadas utilizando los datos de películas que hemos estado analizando"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}