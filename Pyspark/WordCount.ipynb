{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "name": "Lab_1_WordCount",
    "notebookId": 1529163670453288,
    "colab": {
      "name": "WordCount.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv3VP6NwPaLm"
      },
      "source": [
        "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png)  ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
        "# Contando palabras: Construye una aplicacion que cuente palabras de forma eficiente\n",
        "\n",
        "Este laboratorio usara las tecnologias descritas en los materiales del curso sobre Spark para desarrollar una aplicacion de conteo de palabras. \n",
        "\n",
        "Con el uso masivo de Internet y las redes sociales, el volumen de texto no estructurado esta creciendo dramaticamente, y Spark es una gran herramienta para analizar este tipo de datos. En esta PEC, vamos a escribir codigo para encontrar las palabras mas comunes en un texto generado en latin, el ya conocido [Lorem Ipsum](https://www.lipsum.com/).\n",
        "\n",
        "\n",
        "Lo mas interesante de la forma de trabajar en esta practica es que podria escalarse para, por ejemplo, encontrar las palabras mas comunes en Wikipedia.\n",
        "\n",
        "## Durante esta PEC vamos a cubrir:\n",
        "\n",
        "* *Parte 1:* Creación de un RDD y un pair RDD\n",
        "* *Parte 2:* Contar palabras usando un pair RDD\n",
        "* *Parte 3:* Encontrar las palabras individuales y su frecuencia de aparicion media\n",
        "* *Parte 4:* Aplicar las funcionalidades desarrolladas a un archivo de texto* \n",
        "* *Parte 5:* Calcular algunos estadisticos*\n",
        "\n",
        "\n",
        "> Como referencia a todos los detalles de los metodos que se usan en esta practica usar:\n",
        "> * [API Python de Spark](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01GinGx1PaLn"
      },
      "source": [
        "## Parte 1: Creacion de un RDD y un pair RDDs\n",
        "\n",
        "En esta seccion, exploraremos como crear RRDs usando `parallelize` y como aplicar pair RDDs al problema del conteo de palabras.\n",
        "\n",
        "### (0) Configuración del entorno python + spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuQHCDtBPaLo",
        "outputId": "c93f9391-9eeb-4af3-f331-f6bb6de9e580"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark\n",
        "import random\n",
        "sc = pyspark.SparkContext(master=\"local\", appName=\"Gonzalezjulvez\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7Q5hgyqPaLs"
      },
      "source": [
        "### (1a) Creación de un RDD\n",
        "Empezemos generando un RDD a partir de una lista de Python y el metodo `sc.parallelize`. Luego mostraremos por pantalla el tipo de la variable generada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4bfODbuPaLt",
        "outputId": "a2d974a0-010e-4f97-d262-fa6b7939972a"
      },
      "source": [
        "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat']\n",
        "wordsRDD = sc.parallelize(wordsList, 4)\n",
        "# Print out the type of wordsRDD\n",
        "type(wordsRDD)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhOeYqqCPaLw"
      },
      "source": [
        "### (1b) Crear el plural de las palabras y testear\n",
        "\n",
        "Vamos a utilizar una transformacion `map()` para incorporar la letra 's' a cada uno de los strings almacenados en el RDD que acabamos de crear. Vamos a definir una funcion de Python que devuelva una palabra, que se le ha pasado como parametro, incorporando una \"s\" al final de la misma. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqcVJV76PaLy",
        "outputId": "1b7887bc-0d3c-40a9-f39c-144461d735d6"
      },
      "source": [
        "def makePlural(word):\n",
        "    return word + 's'\n",
        "\n",
        "makePlural('cat')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cats'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTxeGLk2PaL5"
      },
      "source": [
        "### (1c) Aplicar `makePlural` a nuestro RDD\n",
        "\n",
        "Ahora es el momento de aplicar nuestra funcion `makePlural()` a todos los elementos del RDD usando una transformacion [map()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.map). Posteriormente ejecutar la accion [collect()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.collect) para obtener el RDD transformado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n28x1I8bPaL5",
        "outputId": "358faa36-a458-4150-a8ff-dc5633df95c9"
      },
      "source": [
        "pluralRDD = wordsRDD.map(makePlural)\n",
        "pluralRDD.collect()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cats', 'elephants', 'rats', 'rats', 'cats']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM_L6OmxPaMB"
      },
      "source": [
        "### (1d) Ejecutar una funcion `lambda` en un `map`\n",
        "\n",
        "Vamos a crear el mismo RDD usando una `lambda` function en lugar de una funcion con nombre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPgkXlqRPaMC",
        "outputId": "602d508b-9d69-4666-f9e6-c4105ee6c997"
      },
      "source": [
        "pluralLambdaRDD = wordsRDD.map(lambda word : makePlural(word))\n",
        "print(pluralLambdaRDD.collect())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cats', 'elephants', 'rats', 'rats', 'cats']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWO-_15vPaMK"
      },
      "source": [
        "### (1e) Numero de caracteres de cada una de las palabras\n",
        "\n",
        "Ahora vamos a usar un `map()` y una funcion lambda `lambda` para obtener el numero de caracteres de cada palabra. Usaremos `collect` para guardar este resultado directamente en una variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt1zO4O7PaMK",
        "outputId": "52b37e5a-e511-4b40-a280-4605ac2ad2d2"
      },
      "source": [
        "pluralLengths = (pluralRDD.map(lambda word : len(word)).collect())\n",
        "print(pluralLengths)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 9, 4, 4, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eBx5-MUPaMR"
      },
      "source": [
        "### (1f) Pair RDDs\n",
        "\n",
        "El siguiente paso para completar nuestro programa de conteo de palabras en crear un nuevo tipo de RDD, llamado pair RDD. Un pair RDD es un RDD donde cada elemento es un tupla del estilo `(k, v)` donde `k` es la clave y `v` es su valor correspondiente. En este ejemplo, crearemos una pair RDD consistente en tuplas con el formato `('<word>', 1)` para cada elemento de nuestro RDD basico.\n",
        "\n",
        "Podemos crear nuestro pair RDD usando una transformacion `map()` con una `lambda()` function que cree un nuevo RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv_pzQ7MPaMR",
        "outputId": "ea1ed68c-30ab-4e65-f3ea-b50ec9c88124"
      },
      "source": [
        "wordPairs = wordsRDD.map(lambda word : (word,1))\n",
        "print(wordPairs.collect())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('cat', 1), ('elephant', 1), ('rat', 1), ('rat', 1), ('cat', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wytu24XKPaMZ"
      },
      "source": [
        "## Parte 2: Contar palabras usando un pair RDD\n",
        "\n",
        "Ahora, contaremos el numero de veces que una palabra en particular aparece en el RDD. Esta operacion se puede realizar de una infinidad de maneras, pero algunas seran mucho menos eficientes que otras.\n",
        "\n",
        "Un solucion muy sencilla seria usar `collect()` sobre todos los elementos devolverlos al driver y alli contarlos. Mientras esta forma de trabajar podria funcionar con textos relativamente cortos, nosotros lo que queremos es poder trabajar con textos de cualquier longitud. Adicionalmente, ejecutar todo el calculo en el driver es mucho mas lento que ejecutarlo en paralelo en los workers. Por estos motivos, en esta practica usaremos operaciones paralelizables.\n",
        "\n",
        "%md\n",
        "### (2a) Usando `groupByKey()`\n",
        "Una primera solucion a nuestro problema, luego veremos que hay otras mucho mas eficientes, se podria basar en la transformacion [groupByKey()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.groupByKey). Como su nombre indica, la transformacion `groupByKey()` agrupa todos los elementos de un RDD que compartan la misma clave en una unica lista dentro de una de las particiones.\n",
        "\n",
        "Esta operacion plantea dos problemas:\n",
        "  + Esta operacion necesita mover todos los valores dentro de la particion adecuada. Esto satura la red. \n",
        "  + Las listas generadas pueden llegar a ser muy grandes llegando incluso a saturar la memoria de alguno de los trabajadadores\n",
        "  \n",
        "Utiliza `groupByKey()` para generar un pair RDD del tipo `('word', iterator)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBRsh9eiPaMa",
        "outputId": "ae6f980d-e452-4dc8-f581-d253cec5824c"
      },
      "source": [
        "wordsGrouped = wordPairs.groupByKey()\n",
        "for key, value in wordsGrouped.collect():\n",
        "    print('{0}: {1}'.format(key, list(value)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: [1, 1]\nelephant: [1]\nrat: [1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igzWT4DxPaMg"
      },
      "source": [
        "### (2b) Utiliza `groupByKey()` para obtener los conteos\n",
        "\n",
        "Usando la transformacion `groupByKey()` crea un RDD que contenga 2 elementos, donde cada uno de ellos sea un par palabra (clave) iterador de Python (valor).\n",
        "\n",
        "Luego suma todos los valores de iterador usando una transformacion `map()`. El resultado debe ser un pair RDD que contenga las parejas (word, count)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t23OoTySPaMg",
        "outputId": "719493f6-78be-486a-de6a-66d971342b3c"
      },
      "source": [
        "wordCountsGrouped = wordsGrouped.map(lambda x : (x[0], len(x[1])))\n",
        "print(wordCountsGrouped.collect())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkD7h5zWPaMo"
      },
      "source": [
        "### (2c) Conteo usando `reduceByKey`\n",
        "\n",
        "Una mejor solucion es comenzar desde un pair RDD y luego usar la transformacion [reduceByKey()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.reduceByKey) para crear un nuevo pair RDD. La transformacion `reduceByKey()` agrupa todas las parejas que comparten la misma clave. Posteriormente aplica la funcion que se le pasa por parametro agrupando los valores de dos en dos. Este proceso se repite iterativamente hasta que obtenemos un unico valor agregado para cada una de las claves del pair RDD. `reduceByKey()` opera aplicando la funcion primero dentro de cada una de las particiones de forma independiente, y posteriormente unicamente comparte los valores agregados entre particiones diferentes, permitiendole escalar de forma eficiente ya que no tiene necesidad de desplazar por la red una gran cantidad de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqIsuTk9PaMp",
        "outputId": "ed8dab91-8110-40e4-fec4-c50a3e52aaf1"
      },
      "source": [
        "wordCounts = wordPairs.reduceByKey(lambda x,y : x+y)\n",
        "print (wordCounts.collect())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuF0GKlRPaMv"
      },
      "source": [
        "### (2d) Ahora todo junto\n",
        "\n",
        "La version mas compleja del codigo ejecuta primero un `map()` sobre el pair RDD, la transformacion `reduceByKey()`, y finalmente la accion `collect()` en una unica linea de codigo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJl6zlvdPaMv",
        "outputId": "55ade1ab-9264-4533-9bda-3b459f3483b5"
      },
      "source": [
        "wordCountsCollected = (wordsRDD\n",
        "                       .map(lambda word : (word,1))\n",
        "                       .reduceByKey(lambda x,y: x+y)\n",
        "                       .collect())\n",
        "print(wordCountsCollected)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWaEGX1QPaM1"
      },
      "source": [
        "## Parte 3: Encontrar las palabras individuales y su frecuencia de aparicion media\n",
        "\n",
        "### (3a) Palabras unicas\n",
        "\n",
        "Calcular el numero de palabras unicas en `wordsRDD`. Puedes utitlziar otros RDDs que hayas creado en esta practica si te resulta mas sencillo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML902zxVPaM2",
        "outputId": "af36694a-cdfc-4db4-a4fc-3cf573367659"
      },
      "source": [
        "uniqueWords = wordCounts.count()\n",
        "print(uniqueWords)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyvOvoOOPaM-"
      },
      "source": [
        "### (3b) Calular la media usando `reduce()`\n",
        "\n",
        "Encuentra la frequencia media de aparicion de palabras en `wordCounts`.\n",
        "\n",
        "Utiliza la accion `reduce()` para sumar los conteos en `wordCounts` y entonces divide por el numero de palabras unicas. Para realizar esto primero aplica un `map()` al pair RDD `wordCounts`, que esta formado por tuplas con el formato (key, value), para convertirlo en un RDD de valores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX3CHA71PaM_",
        "outputId": "dedf5999-c4b0-4075-93b8-672d30bbe293"
      },
      "source": [
        "from operator import add\n",
        "totalCount = (wordCounts\n",
        "              .map(lambda x: x[1])\n",
        "              .reduce(add))\n",
        "average = totalCount / float(wordCounts.count())\n",
        "print(totalCount)\n",
        "print(round(average, 2))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n1.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaW8G9cgPaNF"
      },
      "source": [
        "## Parte 4: Aplicar las funcionalidades desarrolladas a un archivo de texto\n",
        "\n",
        "Para esto hemos de construir una funcion `wordCount`, capaz de trabajar con datos del mundo real que suelen presentan problemas como el uso de mayusculas o minusculas, puntuacion, acentos, etc. Posteriormente, cargar los datos de nuestra fuente de datos y finalmente, calular el conteo de palabras sobre los datos procesados.\n",
        "\n",
        "### (4a) funcion `wordCount`\n",
        "\n",
        "Primero, define una funcion para el conteo de palabras. Deberias reusar las tecnicas que has visto en los apartados anteriores de esta practica. Dicha funcion, ha de tomar un RDD que contenga una lista de palabras, y devolver un pair RDD que contenga todas las palabras con sus correspondientes conteos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T6agsxGPaNH",
        "outputId": "ee3de891-3399-41b6-99bf-2612a09fae6b"
      },
      "source": [
        "\n",
        "def wordCount(wordListRDD):\n",
        "   \n",
        "    return wordListRDD.map(lambda x : (x,1)).reduceByKey(lambda x,y:x+y)\n",
        "\n",
        "print(wordCount(wordsRDD).collect())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7hA6xFwPaNN"
      },
      "source": [
        "### (4b) Mayusculas y puntuacion\n",
        "\n",
        "Los ficheros del mundo real son mucho mas complejos que los que hemos estado usando en esta PAC. Algunos de los problemas que son necesarios de solucionar son:\n",
        "  + Las palabras deben de contarse independientemente de si estan en mayuscula o minuscula (por ejemplo, Spark y spark deberian contarse como la misma palabra).\n",
        "  + Todos los signos de puntuacion han de eliminarse.\n",
        "  + Cualquier espacio al principio o al final de la palabra ha de eliminarse.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKcW5W4ZPaNN",
        "outputId": "cf7453a6-32fb-4970-9577-98a0105bbae8"
      },
      "source": [
        "import re\n",
        "def removePunctuation(text):\n",
        "    lowertext = text.lower()\n",
        "    lowertext_rm = re.sub(r'[^a-z0-9\\s]','',lowertext)\n",
        "    lowertext_final = lowertext_rm.strip()\n",
        "    \n",
        "    return lowertext_final\n",
        "    \n",
        "print(removePunctuation('Hi, you!'))\n",
        "print(removePunctuation(' No under_score!'))\n",
        "print(removePunctuation(' *      Remove punctuation then spaces  * '))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi you\nno underscore\nremove punctuation then spaces\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "galwMxGnPaNT"
      },
      "source": [
        "### (4c) Cargar un fichero de texto\n",
        "\n",
        "Para la siguiente parte, usaremos el texto ya mencionado Lorem Ipsum generado para la pràctica.Para convertir un fichero de texto en un RDD, usaremos el metodo `SparkContext.textFile()`. Tambien usaremos la funcion que acabamos de crear `removePunctuation()` dentro de una transformacion `map()` para eliminar todos los caracteres no alphabeticos, numericos or espacios. Dado que el fichero es bastante grandre, usaremos `take(15)`, de forma que tan solo imprimiremos por pantalla las 15 primeras lineas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW_KO0WXPaNT",
        "outputId": "1897d3c8-ebe3-4705-d9c5-3ffd4931591d"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/home/gonzalezjulvez/Documentos/Projects_Github/Projects/Pyspark'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7ghqDgkPaNX",
        "outputId": "1641f73d-b91a-4f9b-a3b4-acb567261c17"
      },
      "source": [
        "# Tan solo ejecuta este codigo\n",
        "import os.path\n",
        "\n",
        "fileName = os.path.join('/home/gonzalezjulvez/Documentos/Projects_Github/Projects/Pyspark/data/', 'Shakespeare.txt')\n",
        "\n",
        "ShakeRDD = sc.textFile(fileName, 8).map(removePunctuation).filter(lambda x: len(x)>0)\n",
        "ShakeRDD.take(10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['project gutenbergs the complete works of william shakespeare by william shakespeare',\n",
              " 'this ebook is for the use of anyone anywhere in the united states and',\n",
              " 'most other parts of the world at no cost and with almost no restrictions',\n",
              " 'whatsoever  you may copy it give it away or reuse it under the terms',\n",
              " 'of the project gutenberg license included with this ebook or online at',\n",
              " 'wwwgutenbergorg  if you are not located in the united states youll',\n",
              " 'have to check the laws of the country where you are located before using',\n",
              " 'this ebook',\n",
              " 'title the complete works of william shakespeare',\n",
              " 'author william shakespeare']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4nvWTNcPaNa"
      },
      "source": [
        "### (4d) Extraer las palabras de las lineas\n",
        "\n",
        "Antes de poder usar la funcion `wordcount()`, hemos de solucionar dos problemas con el formato del RDD:\n",
        "  + El primer problema es que necesitamos dividir cada linea por sus espacios. ** Esto lo solucionaremos en el apartado (4d). **\n",
        "  + El segundo problema es que necesitamos filtar las lineas completamente vacias. ** Esto lo solucionaremos en el apartado (4e). **\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLDKs9qfPaNa",
        "outputId": "1b3cd725-4ab6-4b0b-e0cc-e13eb64c2176"
      },
      "source": [
        "ShakeWordsRDD = ShakeRDD.flatMap(lambda x: x.split(\" \"))\n",
        "ShakeWordsCount = ShakeWordsRDD.count()\n",
        "print(ShakeWordsRDD.top(5))\n",
        "print(ShakeWordsCount)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['zwounds', 'zwounds', 'zwounds', 'zwounds', 'zwounds']\n976877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ru-y1saPaNf"
      },
      "source": [
        "### (4e) Calcula palabras distintas\n",
        "\n",
        "El siguiente paso es contar cuantas palabras distintas contiene nuestro texto. Puedes usar las transformaciones map() y reduceByKey() ya utilizadas anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1RxwprVPaNg",
        "outputId": "961b31f2-a170-4f5d-d90b-155ef5283718"
      },
      "source": [
        "distintWordsMapRDD = ShakeWordsRDD.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y)\n",
        "\n",
        "distintWordsRDD=distintWordsMapRDD.keys().distinct()\n",
        "\n",
        "print(distintWordsRDD.take(8))   \n",
        "print(distintWordsRDD.count())\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['of', 'other', 'whatsoever', '', 'gutenberg', 'are', 'check', 'where']\n",
            "31566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBQdZAOLPaNo"
      },
      "source": [
        "### (4f) Cuenta las palabras\n",
        "\n",
        "Ahora que tenemos un RDD que contiene solo palabras. El siguiente paso es aplicar la funcion `wordCount()` para producir una lista con los conteos de palabras. Podemos ver las 15 mas comunes usando la accion `takeOrdered()`; sin embargo, como los elementos del RRD son pares, necesitamos una funcion especial que ordene los pares de la forma correcta.\n",
        "\n",
        "Usa las funciones  `wordCount()` y `takeOrdered()` para obtener las 15 palabras mas comunes junto con sus conteos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n4iT40fPaNp",
        "outputId": "4ae2fe37-72c5-4269-88c4-7b4c04cdf949"
      },
      "source": [
        "top15WordsAndCounts = wordCount(ShakeWordsRDD).takeOrdered(15, key = lambda x: -x[1])\n",
        "print(top15WordsAndCounts)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 30205), ('and', 28386), ('i', 21949), ('to', 20923), ('of', 18822), ('a', 16182), ('', 15571), ('you', 14437), ('my', 13180), ('in', 12232), ('that', 11776), ('is', 9713), ('not', 9066), ('with', 8528), ('me', 8263)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTxSlOmuPaNw"
      },
      "source": [
        "## Parte 5: Calcular algunos estadisticos\n",
        "\n",
        "Usando las mismas tecnicas que has aplicado en los ejercicios anteriores responde a las siguientes preguntas:\n",
        "\n",
        "### (5a) ¿Cual es la longitud media de todas las palabras (no repetidas) que aparecen en el texto?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ2X8r_aPaNw",
        "outputId": "8b22442e-7fce-434e-8ef6-376beb4240ef"
      },
      "source": [
        "len_allwords = distintWordsRDD.map(lambda x : len(x)).reduce(add)\n",
        "\n",
        "average_allwords = len_allwords/float(distintWordsRDD.count())\n",
        "\n",
        "print(\"La longitud media de las palabras es \" + str(round(average_allwords,2)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La longitud media de las palabras es 7.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHrjY5BmPaNz"
      },
      "source": [
        "### (5b) ¿Cuantas palabras distintas hay con al menos una 'a' y al menos una 'u' ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqdIObYsPaNz",
        "outputId": "0a0b34cf-ac7a-4cbd-9b8a-0bfe6d8388f1"
      },
      "source": [
        "Words_a_u = distintWordsRDD.filter(lambda x: re.match(r'(\\b\\w*[a]\\w*[u]\\w*\\b)|(\\b\\w*[u]\\w*[a]\\w*\\b)',x))\n",
        "\n",
        "print(\"En el texto seleccionado nos encontramos con {} palabras diferentes que al menos contienen una a y u.\".format(Words_a_u.count()))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En el texto seleccionado nos encontramos con 2600 palabras diferentes que al menos contienen una a y u.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0lixlc6PaN3"
      },
      "source": [
        "### (5c) ¿Cuál es la palabra que más se repite y la que menos?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTLGeH5sPaN6"
      },
      "source": [
        "MapReduceWords = ShakeWordsRDD.map(lambda x: (x,1)).reduceByKey(lambda x,y:x+y)\n",
        "WordsAndCounts= MapReduceWords.takeOrdered(MapReduceWords.count(),key = lambda x: -x[1])\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgIIV3mDPaN9",
        "outputId": "4ae97cad-67ed-445f-8288-444446c2b287"
      },
      "source": [
        "print(\"La palabra mas repetida sería '{}' con {} veces\".format(WordsAndCounts[0][0],WordsAndCounts[0][1]))\n",
        "print(\"La palabra menos repetida sería '{}' con {} veces\".format(WordsAndCounts[-1][0],WordsAndCounts[-1][1]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La palabra mas repetida sería 'the' con 30205 veces\nLa palabra menos repetida sería 'originator' con 1 veces\n"
          ]
        }
      ]
    }
  ]
}