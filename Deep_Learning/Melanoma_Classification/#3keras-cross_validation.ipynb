{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nfrom pathlib import Path\nfrom tensorflow.keras.models import load_model\nimport os\nfrom tensorflow.keras.applications import ResNet50V2\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\ntf.__version__","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"'2.4.1'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '/kaggle/input/'\n\nos.listdir(PATH)","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"['melanoma224', 'dataset-melanoma224']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(f'{PATH}/dataset-melanoma224/subset.csv')\nval = pd.read_csv(f'{PATH}/dataset-melanoma224/val_split.csv')\ntrain.shape, val.shape\n","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"((2220, 8), (10932, 8))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 64\nAUTO = tf.data.experimental.AUTOTUNE # Permite obtener el numero de cpu \n\ndef decode(name, label):\n    img = tf.io.read_file(name)\n    img = tf.image.decode_jpeg(img,channels=3)\n    img = tf.cast(img, tf.float32)\n    return img,label\n\n\ndef load_ds(df):\n    # Le indicamos a tensorflow que da igual el orden de lectura de las imagenes, lo que aumentar치 la velocidad\n    options = tf.data.Options()\n    options.experimental_deterministic = False\n    #---------------\n    imgs , labels = df[\"image_name\"].values, df[\"target\"].values\n    imgs = [f'{PATH}/melanoma224/jpeg224/train/{name}.jpg' for name in imgs]\n    ds = tf.data.Dataset.from_tensor_slices((imgs,labels))\n    ds = ds.with_options(options) # Aplicamos las opciones que hemos puesto\n    ds = ds.map(decode, num_parallel_calls=AUTO) # num_parallel_calls permitira a la funcion map procesar en paralelo tantas imagenes como le pongamos\n                                                 # maximo el numero de cpu que tenga el ordenador por eso usamo la variable AUTO\n    df = ds.cache() # Cada epochs se leen las imagenes y es preferible cargar nuestro datasets en cache\n    ds = ds.shuffle(2048)\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(buffer_size = AUTO) # Mientras la gpu esta calculando la cpu vaya leyendo imagenes\n    return ds\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FOLDS = 3 # El numero de folds comun es 5 y en datasets peque침os 10\naucs = []\nskf = StratifiedKFold(n_splits=FOLDS, random_state=42, shuffle=True) # Nor permitir치 crear subgrupos stratificados\n\nfor f, (train_index,val_index) in enumerate(skf.split(X=np.zeros(len(train)), y=train[\"target\"])): # Como solo nos interesa el stratified por los indices del targets podemos ponerle\n                                                                                                   # a la X secuencia de ceros de la longitud de dataframe\n    print(\"Fold: \",f+1)\n    \n    train_fold = train.iloc[train_index]\n    val_fold = train.iloc[val_index]\n    \n    # Ahora deberemos meter todo aqui\n    train_ds = load_ds(train_fold)\n    val_ds = load_ds(val_fold)\n    \n    IMAGE_SIZE = (224,224,3)\n\n    encoder = ResNet50V2(\n        include_top=False,\n        input_shape=IMAGE_SIZE,\n        weights='imagenet'\n    )\n    encoder.trainable=False\n    inputs = keras.Input(shape=IMAGE_SIZE)\n    x = keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n    x = encoder(x, training = False)\n    x = keras.layers.GlobalAveragePooling2D()(x)\n    ouputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n    model = keras.Model(inputs, ouputs)\n    #model.summary()\n    \n    #Compilamos el modelo\n    model.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss=keras.losses.BinaryCrossentropy(),\n    metrics=[keras.metrics.AUC(name=\"auc\")]\n    )\n    # Creamos nuestra callbacks\n    filepath = f\"kaggle/working/checkpoints/checkpoint\"\n    cb = tf.keras.callbacks.ModelCheckpoint(\n    filepath=filepath,\n    monitor=\"val_auc\",\n    verbose=1,\n    save_best_only=True,\n    save_weights_only=True, # Guardar todo el modelo o solo los pesos\n    mode=\"max\", # Guardara el valor maximo del parametro que monitorizamos, en caso de loss poner \"min\"\n    )\n    \n    #Entrenamos nuestro modelo\n    model.fit(train_ds,\n          epochs=10,\n          validation_data=val_ds,\n          validation_steps=10,\n          callbacks=[cb])\n    # Al final de cada for cargamos los mejores pesos\n    model.load_weights(filepath)\n    model.save(f\"/kaggle/working/model{f+1}.h5\")# Deberemos indicar nombres diferentes para guardar los diferentes modelos que generemos\n    \n    # Cargamos las metricas\n    _, auc = model.evaluate(val_ds) # Evaluate nos devolver치 la \"loss\" y la metrica \"auc\"\n    aucs.append(auc)\n    \n    \n","execution_count":5,"outputs":[{"output_type":"stream","text":"Fold:  1\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n94674944/94668760 [==============================] - 3s 0us/step\nEpoch 1/10\n24/24 [==============================] - 24s 402ms/step - loss: 0.2973 - auc: 0.4594 - val_loss: 0.1191 - val_auc: 0.2504\n\nEpoch 00001: val_auc improved from -inf to 0.25040, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 2/10\n24/24 [==============================] - 5s 162ms/step - loss: 0.1017 - auc: 0.4802 - val_loss: 0.1160 - val_auc: 0.3840\n\nEpoch 00002: val_auc improved from 0.25040 to 0.38402, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 3/10\n24/24 [==============================] - 5s 170ms/step - loss: 0.1188 - auc: 0.6782 - val_loss: 0.1055 - val_auc: 0.4832\n\nEpoch 00003: val_auc improved from 0.38402 to 0.48321, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 4/10\n24/24 [==============================] - 5s 165ms/step - loss: 0.0777 - auc: 0.8005 - val_loss: 0.1024 - val_auc: 0.5204\n\nEpoch 00004: val_auc improved from 0.48321 to 0.52037, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 5/10\n24/24 [==============================] - 5s 165ms/step - loss: 0.0672 - auc: 0.7903 - val_loss: 0.0824 - val_auc: 0.6148\n\nEpoch 00005: val_auc improved from 0.52037 to 0.61476, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 6/10\n24/24 [==============================] - 5s 178ms/step - loss: 0.0692 - auc: 0.8202 - val_loss: 0.0903 - val_auc: 0.6210\n\nEpoch 00006: val_auc improved from 0.61476 to 0.62104, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 7/10\n24/24 [==============================] - 5s 163ms/step - loss: 0.0566 - auc: 0.9248 - val_loss: 0.0687 - val_auc: 0.7500\n\nEpoch 00007: val_auc improved from 0.62104 to 0.74996, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 8/10\n24/24 [==============================] - 5s 167ms/step - loss: 0.0425 - auc: 0.9010 - val_loss: 0.1029 - val_auc: 0.6308\n\nEpoch 00008: val_auc did not improve from 0.74996\nEpoch 9/10\n24/24 [==============================] - 5s 170ms/step - loss: 0.0575 - auc: 0.9587 - val_loss: 0.0936 - val_auc: 0.6060\n\nEpoch 00009: val_auc did not improve from 0.74996\nEpoch 10/10\n24/24 [==============================] - 5s 161ms/step - loss: 0.0419 - auc: 0.9233 - val_loss: 0.0967 - val_auc: 0.5953\n\nEpoch 00010: val_auc did not improve from 0.74996\n12/12 [==============================] - 2s 125ms/step - loss: 0.0923 - auc: 0.6299\nFold:  2\nEpoch 1/10\n24/24 [==============================] - 9s 210ms/step - loss: 0.7096 - auc: 0.3921 - val_loss: 0.1247 - val_auc: 0.4053\n\nEpoch 00001: val_auc improved from -inf to 0.40533, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 2/10\n24/24 [==============================] - 5s 165ms/step - loss: 0.1279 - auc: 0.4403 - val_loss: 0.1404 - val_auc: 0.4275\n\nEpoch 00002: val_auc improved from 0.40533 to 0.42749, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 3/10\n24/24 [==============================] - 5s 165ms/step - loss: 0.1150 - auc: 0.4244 - val_loss: 0.1227 - val_auc: 0.4087\n\nEpoch 00003: val_auc did not improve from 0.42749\nEpoch 4/10\n24/24 [==============================] - 5s 174ms/step - loss: 0.1373 - auc: 0.4250 - val_loss: 0.1095 - val_auc: 0.4792\n\nEpoch 00004: val_auc improved from 0.42749 to 0.47917, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 5/10\n24/24 [==============================] - 5s 163ms/step - loss: 0.0959 - auc: 0.5120 - val_loss: 0.0949 - val_auc: 0.5428\n\nEpoch 00005: val_auc improved from 0.47917 to 0.54278, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 6/10\n24/24 [==============================] - 5s 174ms/step - loss: 0.1015 - auc: 0.6288 - val_loss: 0.0979 - val_auc: 0.5987\n\nEpoch 00006: val_auc improved from 0.54278 to 0.59866, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 7/10\n24/24 [==============================] - 5s 170ms/step - loss: 0.0905 - auc: 0.6419 - val_loss: 0.0907 - val_auc: 0.6783\n\nEpoch 00007: val_auc improved from 0.59866 to 0.67834, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 8/10\n24/24 [==============================] - 5s 169ms/step - loss: 0.0701 - auc: 0.7485 - val_loss: 0.0881 - val_auc: 0.7262\n\nEpoch 00008: val_auc improved from 0.67834 to 0.72618, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 9/10\n24/24 [==============================] - 5s 168ms/step - loss: 0.0648 - auc: 0.8330 - val_loss: 0.0829 - val_auc: 0.7664\n\nEpoch 00009: val_auc improved from 0.72618 to 0.76639, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 10/10\n24/24 [==============================] - 5s 174ms/step - loss: 0.0602 - auc: 0.7891 - val_loss: 0.0740 - val_auc: 0.8011\n\nEpoch 00010: val_auc improved from 0.76639 to 0.80113, saving model to kaggle/working/checkpoints/checkpoint\n12/12 [==============================] - 2s 97ms/step - loss: 0.0770 - auc: 0.7844\nFold:  3\nEpoch 1/10\n24/24 [==============================] - 9s 219ms/step - loss: 0.3188 - auc: 0.2922 - val_loss: 0.1263 - val_auc: 0.4719\n\nEpoch 00001: val_auc improved from -inf to 0.47193, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 2/10\n24/24 [==============================] - 5s 162ms/step - loss: 0.1024 - auc: 0.3578 - val_loss: 0.1105 - val_auc: 0.5259\n\nEpoch 00002: val_auc improved from 0.47193 to 0.52594, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 3/10\n24/24 [==============================] - 5s 164ms/step - loss: 0.1119 - auc: 0.5261 - val_loss: 0.1016 - val_auc: 0.4317\n\nEpoch 00003: val_auc did not improve from 0.52594\nEpoch 4/10\n24/24 [==============================] - 5s 169ms/step - loss: 0.0690 - auc: 0.7127 - val_loss: 0.1041 - val_auc: 0.5068\n\nEpoch 00004: val_auc did not improve from 0.52594\nEpoch 5/10\n24/24 [==============================] - 5s 168ms/step - loss: 0.0843 - auc: 0.7393 - val_loss: 0.0819 - val_auc: 0.5568\n\nEpoch 00005: val_auc improved from 0.52594 to 0.55679, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 6/10\n24/24 [==============================] - 5s 166ms/step - loss: 0.0628 - auc: 0.7910 - val_loss: 0.1070 - val_auc: 0.5788\n\nEpoch 00006: val_auc improved from 0.55679 to 0.57882, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 7/10\n24/24 [==============================] - 5s 174ms/step - loss: 0.0634 - auc: 0.8725 - val_loss: 0.0973 - val_auc: 0.6043\n\nEpoch 00007: val_auc improved from 0.57882 to 0.60430, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 8/10\n24/24 [==============================] - 5s 163ms/step - loss: 0.0456 - auc: 0.9398 - val_loss: 0.0991 - val_auc: 0.6125\n\nEpoch 00008: val_auc improved from 0.60430 to 0.61246, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 9/10\n24/24 [==============================] - 5s 168ms/step - loss: 0.0521 - auc: 0.9546 - val_loss: 0.0992 - val_auc: 0.6244\n\nEpoch 00009: val_auc improved from 0.61246 to 0.62440, saving model to kaggle/working/checkpoints/checkpoint\nEpoch 10/10\n24/24 [==============================] - 5s 168ms/step - loss: 0.0425 - auc: 0.9498 - val_loss: 0.1050 - val_auc: 0.6356\n\nEpoch 00010: val_auc improved from 0.62440 to 0.63563, saving model to kaggle/working/checkpoints/checkpoint\n12/12 [==============================] - 2s 103ms/step - loss: 0.0929 - auc: 0.6393\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"aucs","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"[0.629880428314209, 0.7843614816665649, 0.639297366142273]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(aucs),np.std(aucs)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(0.6845130920410156, 0.07070806348465987)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest = pd.read_csv(f'{PATH}/melanoma224/test.csv')\nBATCH_SIZE = 64\n\ndef decode_test(name):\n    img = tf.io.read_file(name)\n    img = tf.image.decode_jpeg(img,channels=3)\n    img = tf.cast(img, tf.float32)\n    return img\n\n\ndef load_test_ds(df):\n    imgs  = df[\"image_name\"].values\n    imgs = [f'{PATH}/melanoma224/jpeg224/test/{name}.jpg' for name in imgs]\n    ds = tf.data.Dataset.from_tensor_slices(imgs)\n    ds = ds.map(decode_test, num_parallel_calls=AUTO)\n    ds = ds.batch(BATCH_SIZE)\n    return ds","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ds = load_test_ds(test)\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Como tenemos tres modelos lo que haremos sera calcular las predicciones con los tres\npreds = []\nfor f in range(1,FOLDS+1):\n    print(\"Folds:\", f)\n    model_fold = load_model(f\"/kaggle/working/model{f}.h5\")\n    probas = model_fold.predict(test_ds)\n    preds.append(probas)","execution_count":11,"outputs":[{"output_type":"stream","text":"Folds: 1\nFolds: 2\nFolds: 3\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ahora haremos una media de las tres predicciones \npreds_mean = np.mean(preds, axis=0)\npreds_mean","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"array([[0.01373591],\n       [0.00668238],\n       [0.01764069],\n       ...,\n       [0.01693267],\n       [0.00294129],\n       [0.03003343]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n    'image_name':test['image_name'].values,\n    'target':preds_mean.ravel()\n})","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"/kaggle/working/submission.csv\", index=False)\n","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}