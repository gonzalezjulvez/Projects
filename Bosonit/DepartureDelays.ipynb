{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"devtools\")\n",
    "devtools::install_github(\"hadley/devtools\") ## for latest version\n",
    "devtools::install_github(\"rstudio/sparklyr\")\n",
    "devtools::install_github(\"tidyverse/dplyr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade tornado==5.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(SparkR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkR.session(master = \"local[*]\", sparkConfig = list(spark.driver.memory = \"2g\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crearemos el esquema de nuestros datos \n",
    "schema_departure <- structType(structField(\"date\",\"int\"),\n",
    "                    structField(\"delay\",\"int\"),\n",
    "                    structField(\"distance\",\"int\"),\n",
    "                    structField(\"origin\",\"string\"),\n",
    "                    structField(\"destination\",\"string\"))\n",
    "# Realizamos la lectura de nuestro datasets indicando una serie de parametros como el formato de los datos, la cabecera o el schema a seguir.\n",
    "df_departure <- read.df(\"data/departuredelays.csv\", source = \"csv\", header=\"true\", schema= schema_departure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-award",
   "metadata": {},
   "source": [
    "\n",
    "## Mostrar los dataframes\n",
    "- head\n",
    "- show\n",
    "- showDF\n",
    "- take\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por defecto muestra las 6 primeras líenas\n",
    "head(df_departure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(df_departure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por defecto muestra las 20 primeras filas\n",
    "# Vertical nos permite monstrar un dataframe por registro siendo las en este caso las filas el nombre de nuestras columnas\n",
    "showDF(df_departure,numRows = 15, truncate = TRUE, vertical = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es obligatorio indicar el numero de filas que quiere que te muestré\n",
    "take(df_departure, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-magic",
   "metadata": {},
   "source": [
    "## Primera exploración de los datos:\n",
    "- summary\n",
    "- describe\n",
    "- summarize\n",
    "- printSchema\n",
    "- str \n",
    "- dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos arrojará una tabla indicando las principales medidas estadisticas de nuestro datasets\n",
    "showDF(summary(df_departure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al igual que la anterior formula describe nos muestra tambien medidas estadisticas pero sin los percentiles, \n",
    "showDF(describe(df_departure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(summarize(groupBy(df_departure,df_departure$origin), avg = avg(df_departure$delay)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra la estructura de un SparkDataFrame, incluidos los nombres de columna, los tipos de columna, así como una pequeña muestra de filas.\n",
    "str(df_departure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve todos los nombres de columna y sus tipos de datos como una lista\n",
    "dtypes(df_departure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el esquema de nuestro conjunto de datos\n",
    "printSchema(df_departure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-consultation",
   "metadata": {},
   "source": [
    "## SparkSQL\n",
    "\n",
    "- createOrReplaceTempView\n",
    "- sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crearemos una vista temporal para poder utilizar el lenguaje SQL\n",
    "createOrReplaceTempView(df_departure,\"us_delay_flights_tbl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-pottery",
   "metadata": {},
   "source": [
    "### Filtra los vuelos con mas de 1000 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monstrarmos el origen, destino y distancia para los vuelos mas de 1000\n",
    "df_mas_1000_distance <- sql(\"SELECT distance, origin, destination\n",
    "                               FROM us_delay_flights_tbl WHERE distance > 1000\n",
    "                               ORDER BY distance DESC\")\n",
    "showDF(df_menos_1000_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-intelligence",
   "metadata": {},
   "source": [
    "### Categoriza los vuelos segun el delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizaremos la clausula Case para categorizar los vuelos segun el tiempo del delay\n",
    "df_delay <- sql(\"SELECT delay, origin, destination,\n",
    "                  CASE\n",
    "                    WHEN delay > 360 THEN 'Very Long Delays'\n",
    "                    WHEN delay > 120 AND delay < 360 THEN 'Long Delays'\n",
    "                    WHEN delay > 60 AND delay < 120 THEN 'Short Delays'\n",
    "                    WHEN delay > 0 and delay < 60 THEN 'Tolerable Delays'\n",
    "                    WHEN delay = 0 THEN 'No Delays'\n",
    "                    ELSE 'Early'\n",
    "                  END AS Flight_Delays\n",
    "                  FROM us_delay_flights_tbl\n",
    "                  ORDER BY origin, delay DESC\")\n",
    "showDF(df_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-frederick",
   "metadata": {},
   "source": [
    "## Manipulacion de los datos\n",
    "- select\n",
    "- filter\n",
    "- orderBy\n",
    "- distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos las diferentes API de R para seleccionar los vuelos con mas de 1000 de distancia\n",
    "\n",
    "# Podemos indicar las columnas mediante \"nombre_columna\" o datasets$nombre_columna\n",
    "\n",
    "temp <- filter(df_departure,\"distance > 1000\")\n",
    "temp <- select(temp,\"distance\" , \"origin\", \"destination\")\n",
    "temp <- orderBy(temp, desc(temp$distance))\n",
    "flights_distance_plus_1000 <- distinct(temp)\n",
    "showDF(flights_distance_plus_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-titanium",
   "metadata": {},
   "source": [
    "### Número de destinos diferentes por origen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Destinos <- agg(groupBy(df_departure, \"origin\"), numero_destinos = countDistinct(df_departure$destination))\n",
    "\n",
    "showDF(orderBy(Destinos,desc(Destinos$numero_destinos)), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-curve",
   "metadata": {},
   "source": [
    "## Guardar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardaremos nuestros datos en formato parquet mediante la funcion write.df o write.parquet\n",
    "# De forma similar podremos guardar el datasets en los diferentes formatos soportados por Spark R (Json,CSV,TXT,Parquet, ORC, jbdc), liberías externas (Avro)\n",
    "write.df(df_departure, path = \"data/departuredelays.parquet\", source = \"parquet\", mode = \"overwrite\")\n",
    "\n",
    "\n",
    "#Cargamos los datos de parquet\n",
    "df_more_1000_distance <- read.df(\"data/departuredelays.parquet\", source = \"parquet\", header=\"true\", inferSchema=\"true\")\n",
    "showDF(df_more_1000_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-texas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-tuition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-sheet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
